{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "We will look at helical coordinates and the steps required to set up and utilize them. You still start by creating helical filters of different sizes and dimensions and test the convolution and deconvolution with these filters. Then you will precondition an optimization problem using helical deconvolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the textbook we saw how helical filters can handle any number of dimensions efficiently and easily. Moreover, they allow several operations, such as deconvolution and factorization, in any dimensions using corresponding 1D operators. This makes helical filters and operators very useful for many applications, especially preconditioning.\n",
    "\n",
    "Preconditioning can provide great speed up and efficiency improvements for optimization. However, it requires knowing the inverse of the regularization operator. In many cases, it is very difficult to estimate the inverse operator. However, helical deconvolution allows us to divide by the filter response of the operator, assuming stationarity, without having to know the inverse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your assignment\n",
    "\n",
    "In this lab, you will explore and utilize the python helix classes that we wrote in class a few weeks ago. We encourage you to use any dataset that is in the ``data`` directory found within your ``GP211`` directory or any previous datasets that we have used thus far in the labs. You can use the other labs to help you read in the datasets. Also, the terminal option within the jupyter notebook is a nice way to quickly explore the directory structure and open files with standard Unix text editors such as ``vim`` and ``nano``.\n",
    "\n",
    "As part of your assignment, you will first creat 2D helix filters and test their convolution and deconvolution operators. Then, you will run and compare a regularized optimization to a preconditioned optimization. We will only be providing you with this helix filter codes that we created in class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helix filter code\n",
    "\n",
    "Please find the codes for HelixFilter.py, Helicon.py and Polydiv.py that we implemented together in class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helix2Cart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING! DATAPATH not found. The folder /tmp will be used to write binary files\n"
     ]
    }
   ],
   "source": [
    "import giee\n",
    "import copy\n",
    "\n",
    "class helix2cart:\n",
    "    \"\"\"Convert to and from cartesian and helix space\"\"\"\n",
    "    def __init__(self,nd):\n",
    "        \"\"\"Initialize conversion\n",
    "        \n",
    "             nd - Data dimensions\"\"\"\n",
    "        if not isinstance(nd,list):\n",
    "            raise Exception(\"Expecting nd to be a list\")\n",
    "    \n",
    "        self._ndim=copy.deepcopy(nd)\n",
    "        self._b=[1]\n",
    "        sz=1\n",
    "        for n in self._ndim:\n",
    "            if not isinstance(n,int):\n",
    "                raise Exception(\"Expecting a list of ints\")\n",
    "            sz=sz*n\n",
    "            self._b.append(sz)\n",
    "    \n",
    "\n",
    "    def toCart(self,hlx):\n",
    "        cart=[0]*len(self._ndim)\n",
    "        lft=hlx\n",
    "        for i in range(len(self._ndim)-1,-1,-1):\n",
    "            cart[i]=int(lft/self._b[i])\n",
    "            lft-=cart[i]*self._b[i]\n",
    "        return cart\n",
    "    \n",
    "    \n",
    "    def toHelix(self,cart):\n",
    "        \"\"\"Convert from cartesian space to helix space\"\"\"\n",
    "        if len(cart) != len(self._ndim):\n",
    "            raise Exception(\"Expecting cart to be same size as data\")\n",
    "        hlx=0\n",
    "        for i in range(len(self._ndim)):\n",
    "            if not isinstance(cart[i],int):\n",
    "                raise Exception(\"Expecting cart to be a list of ints\")\n",
    "            hlx+=cart[i]*self._b[i]\n",
    "        return hlx "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HelixFilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Helix2cart\n",
    "import giee\n",
    "\n",
    "class helixFilter(giee.vector):\n",
    "    \"\"\"Class for defining a filter on a helix\"\"\"\n",
    "    def __init__(self,nd,**kw):\n",
    "        \"\"\"Option 1:\n",
    "           nelem [int] Number of elements in filter\n",
    "        \n",
    "           Option 2:\n",
    "            filt -  Filter to make a copy of\n",
    "            \n",
    "            Option 3:\n",
    "             n - Length of a box describing the filter. First axis must be odd\n",
    "        \n",
    "        \"\"\"\n",
    "        self._nd=nd\n",
    "\n",
    "        if \"nelem\" in kw: \n",
    "            if not isinstance(kw[\"nelem\"],int):\n",
    "                raise Exception(\"Expecting nelem to be integer\")\n",
    "            super().__init__([kw[\"nelem\"]])\n",
    "            self._lags=[0]*self.getNdArray().shape[0]\n",
    "\n",
    "        elif \"filt\" in kw: \n",
    "            if not isinstance(kw[\"filt\"],helixFilter):\n",
    "                raise Exception(\"Expecting filter to be helixFilter\")\n",
    "            super().__init__(kw[\"filt\"]._hyper,arr=kw[\"filt\"].getNdArray())\n",
    "            self._lags=kw[\"filt\"]._lags\n",
    "\n",
    "        elif \"n\" in kw: \n",
    "            self._lags=[]\n",
    "            if not isinstance(kw[\"n\"],list):\n",
    "                raise Exception(\"Expecting n to be a list\")\n",
    "  \n",
    "            if len(kw[\"n\"]) > len(nd):\n",
    "                raise Exception(\"Box dimensions larger than data\")\n",
    "            if len(kw[\"n\"]) >3 :\n",
    "                raise Exception(\"Can only handle 3-D\")\n",
    "            n=kw[\"n\"]\n",
    "            for i in range (len(nd),3):\n",
    "                nd.append(1)\n",
    "            for i in range(len(n),3):\n",
    "                n.append(1)\n",
    "            for i in range(3):\n",
    "                if not isinstance(nd[i],int):\n",
    "                    raise Exception(\"Expecting nd elements to be int\")\n",
    "                if not isinstance(n[i],int):\n",
    "                    raise Exception(\"Expecting n elements to be int\") \n",
    "                if n[i]> nd[i]:\n",
    "                    raise Exception(\"Expecting n to be smaller than nd\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyOperator\n",
    "import HelixFilter\n",
    "from numba import jit \n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class helicon(pyOperator.Operator):\n",
    "    \"\"\" Filtering with the helix\"\"\"\n",
    "    def __init__(self,model,data,filt):\n",
    "        \"\"\" \n",
    "            model - vector with hypercube and ndArray\n",
    "            data  - vector with hypercube and ndArray\n",
    "            filt  - HelixFilter\n",
    "        \n",
    "        \"\"\"\n",
    "    \n",
    "        if not model.checkSame(data):\n",
    "            raise Exception(\"Model and data must be same space\")\n",
    "    \n",
    "        try:\n",
    "            h  =  model.getHyper()\n",
    "            m  =  model.getNdArray()\n",
    "            h2 = data.getHyper()\n",
    "            d  = data.getNdArray()\n",
    "        except:\n",
    "            raise Exception(\"Model must have a hypercube and numpy representation\")\n",
    "    \n",
    "        if not isinstance(filt,HelixFilter.helixFilter):\n",
    "            raise Exception(\"Expecting filt to be a helix filter\")\n",
    "    \n",
    "        ns=h.getNs()\n",
    "        self._n123=h.getN123()\n",
    "\n",
    "        if len(ns) !=len(filt._nd):\n",
    "            for i in range(len(ns),len(filt._nd)):\n",
    "                if filt._nd[i] >1: \n",
    "                    raise Exception(\"Expecting filter n to be the same as data\")\n",
    "    \n",
    "        for i in range(len(ns)):\n",
    "            if ns[i] != filt._nd[i]:\n",
    "                raise Exception(\"Expecting filter n to be the same ss data\")\n",
    "\n",
    "        super().__init__(model,data)\n",
    "        self._filt=filt\n",
    "    \n",
    "    def forward(self,add,model,data):\n",
    "        \"\"\"Forward helix filtering\"\"\"\n",
    "        self.checkDomainRange(model,data)\n",
    "        if not add:\n",
    "            data.zero()\n",
    "        m=np.reshape(model.getNdArray(),(self._n123,))\n",
    "        d=np.reshape(data.getNdArray(),(self._n123,))\n",
    "        heliconFor(m,d,self._filt._lags,self._filt.getNdArray())\n",
    "        \n",
    "    def adjoint(self,add,model,data):\n",
    "        \"\"\"Forward helix filtering\"\"\"\n",
    "        self.checkDomainRange(model,data)\n",
    "        if not add:\n",
    "            model.zero()\n",
    "        m=np.reshape(model.getNdArray(),(self._n123,))\n",
    "        d=np.reshape(data.getNdArray(),(self._n123,))\n",
    "        heliconAdj(m,d,self._filt._lags,self._filt.getNdArray())\n",
    "\n",
    "@jit()\n",
    "def heliconFor(model,data,lags,coefs):\n",
    "\n",
    "    for i in range(model.shape[0]):\n",
    "        data[i]+=model[i]\n",
    "        for ilag in range(len(lags)):\n",
    "            im=i-lags[ilag]\n",
    "            if im>=0:\n",
    "                data[i]+=model[im]*coefs[ilag]\n",
    "\n",
    "@jit()\n",
    "def heliconAdj(model,data,lags,coefs):\n",
    "    for i in range(model.shape[0]):\n",
    "        model[i]+=data[i]\n",
    "        for ilag in range(len(lags)):\n",
    "            im=i-lags[ilag]\n",
    "            if im>=0:\n",
    "                model[im]+=data[i]*coefs[ilag]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Polydiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyOperator\n",
    "import HelixFilter\n",
    "import numpy as np\n",
    "\n",
    "from numba import jit \n",
    "class polydiv(pyOperator.Operator):\n",
    "    \"\"\" Inverse filtering with the helix\"\"\"\n",
    "    def __init__(self,model,data,filt):\n",
    "        \"\"\" \n",
    "            model - vector with hypercube and ndArray\n",
    "            data  - vector with hypercube and ndArray\n",
    "            filt  - HelixFilter\n",
    "        \n",
    "        \"\"\"\n",
    "    \n",
    "        if not model.checkSame(data):\n",
    "            raise Exception(\"Model and data must be same space\")\n",
    "    \n",
    "        try:\n",
    "            h=model.getHyper()\n",
    "            m=model.getNdArray()\n",
    "            h2=data.getHyper()\n",
    "            d=data.getNdArray()\n",
    "        except:\n",
    "            raise Exception(\"Model must have a hypercube and numpy representation\")\n",
    "    \n",
    "        if not isinstance(filt,HelixFilter.helixFilter):\n",
    "            raise Exception(\"Expecting filt to be a helix filter\")\n",
    "    \n",
    "        ns=h.getNs()\n",
    "        self._n123=h.getN123()\n",
    "        if len(ns) !=len(filt._nd):\n",
    "            for i in range(len(ns),len(filt._nd)):\n",
    "                if filt._nd[i] >1: \n",
    "                    raise Exception(\"Expecting filter n to be the same as data\")\n",
    "    \n",
    "        for i in range(len(ns)):\n",
    "            if ns[i] != filt._nd[i]:\n",
    "                raise Exception(\"Expecting filter n to be the same ss data\")\n",
    "\n",
    "        super().__init__(model,data)\n",
    "        self._filt=filt\n",
    "        self._tt=model.clone()\n",
    "        self._t=np.reshape(self._tt.getNdArray(),(self._n123,))\n",
    "\n",
    "    def forward(self,add,model,data):\n",
    "        \"\"\"Forward helix filtering\"\"\"\n",
    "        self.checkDomainRange(model,data)\n",
    "\n",
    "        if not add:\n",
    "            data.zero()\n",
    "        self._tt.scaleAdd(model,0.,1.)\n",
    "        m=np.reshape(model.getNdArray(),(self._n123,))\n",
    "        d=np.reshape(data.getNdArray(),(self._n123,))\n",
    "        polydivFor(m,d,\\\n",
    "                   self._filt._lags,self._filt.getNdArray(),self._t)\n",
    "        data.scaleAdd(self._tt)\n",
    "\n",
    "    def adjoint(self,add,model,data):\n",
    "        \"\"\"Forward helix filtering\"\"\"\n",
    "        self.checkDomainRange(model,data)\n",
    "        if not add:\n",
    "            model.zero()\n",
    "        self._tt.scaleAdd(data,0.,1.)\n",
    "        m=np.reshape(model.getNdArray(),(self._n123,))\n",
    "        d=np.reshape(data.getNdArray(),(self._n123,))\n",
    "\n",
    "        polydivAdj(m,d,\\\n",
    "                   self._filt._lags,self._filt.getNdArray(),self._t)\n",
    "        model.scaleAdd(self._tt)\n",
    "\n",
    "\n",
    "@jit()\n",
    "def polydivFor(model,data,lags,coefs,tt):\n",
    "\n",
    "    for i in range(model.shape[0]):\n",
    "        for ilag in range(len(lags)):\n",
    "            im=i-lags[ilag]\n",
    "            if im>=0:\n",
    "                tt[i] -= tt[im]*coefs[ilag]\n",
    "@jit()\n",
    "def polydivAdj(model,data,lags,coefs,tt):\n",
    "    for i in range(model.shape[0]-1,-1,-1):\n",
    "        for ilag in range(len(lags)):\n",
    "            im=i+lags[ilag]\n",
    "            if im<model.shape[0]:\n",
    "                tt[i]-=tt[im]*coefs[ilag]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helix Filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create and plot a 2D model with some spares spikes and make sure some spikes are close to the edges and cordners. Create a helix filter of your chocice (be creative) for the spiky model. Apply and plot the forward convolution of the filter on the model to see the filter response. Is this response what you expect? How does the filter behave around the edges?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Apply and plot the adjoint convolution on the result of the previous question. Is the adjoint a good approximation to the inverse? Why are the results symmetric at each spike location?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Apply and plot the forward deconvolution of the filter on the model to see the inverse filter response. How does the inverse response compare to the filter itself (please be elaborate)?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Apply and plot the adjoint deconvolution on the result of the previous question. How does this result compare to the results in the second question (again, please be elaborate)?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Use the deconvolution operator on the results of the second question to remove the effect of the adjoint convolution operator. Did the deconvolution operator correctly remove the adjoint convolution effects?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Use the deconvolution operator on the results of the previous question to remove the effect of the forward convolution operator. Did the deconvolution operator recover the original spiky model? Plot your results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preconditioning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Set up a regularized optimization of your choice. You can either pick a problem done in a previous lab or make a new one given the datasets and operators available to you. The problem you pick should require regularization to give proper results where the regularization operator is stationary but not only diagonal. Clearly define the objective function and all of its components."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Why does this problem need to be regularized?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9.  Run the regularized solver and plot the original data, the inverted model, the reconstructed data and the curve of the residual norm as a function of iterations (might be good to show the logarithm of this curve normalized by its maximum value). How well did the optimization solve the problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Rewrite the objective function after preconditioning and clearly define all of its components\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. Convert your regularization operator into a helix filter and run the preconditioned solver with the deconvolution operator as the inverse of the regularization operator. Plot the original data, the inverted model, the reconstructed data and the curve of the residual norm as a function of iterations. How does the preconditioned solver compare to the regularized solver in both accuracy and convergence rate?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra credit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. If the regularization operator is non-stationary or non-invertible, can we do an approximate preconditioning? What would the objective function be in that case?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
